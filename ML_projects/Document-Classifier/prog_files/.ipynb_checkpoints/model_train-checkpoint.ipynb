{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00841883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 15:22:47.908005: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "#Importing Layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D,Dropout,Flatten,MaxPooling2D\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7587a007",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/fansan/Desktop/Document-Classifier/Dataset/data/train/aadhaar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4952/2741288847.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mvoter_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCATEGORIES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0maadhaar_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maadhaar_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mdl_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mpan_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpan_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/fansan/Desktop/Document-Classifier/Dataset/data/train/aadhaar'"
     ]
    }
   ],
   "source": [
    "#dir_paths  \n",
    "train_dir = \"/home/fansan/Desktop/Document-Classifier/Dataset/data/train\"\n",
    "test_dir = \"/home/fansan/Desktop/Document-Classifier/Dataset/data/test\"\n",
    "valid_dir=\"/home/fansan/Desktop/Document-Classifier/Dataset/data/valid\"\n",
    "CATEGORIES = [\"aadhaar\", \"dl\", \"pan\", \"voter\"]\n",
    "\n",
    "aadhaar_dir=os.path.join(train_dir,CATEGORIES[0])\n",
    "dl_dir=os.path.join(train_dir,CATEGORIES[1])\n",
    "pan_dir=os.path.join(train_dir,CATEGORIES[2])\n",
    "voter_dir=os.path.join(train_dir,CATEGORIES[3])\n",
    "\n",
    "aadhaar_list=os.listdir(aadhaar_dir)\n",
    "dl_list=os.listdir(dl_dir)\n",
    "pan_list=os.listdir(pan_dir)\n",
    "voter_list=os.listdir(voter_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0311ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=[]\n",
    "\n",
    "for folder in os.listdir(train_dir):\n",
    "    sub_dir=train_dir+\"/\"+folder\n",
    "    for img in os.listdir(sub_dir):\n",
    "        image_dir=sub_dir+\"/\"+img\n",
    "        img_arr=cv2.imread(image_dir)\n",
    "        img_arr=cv2.resize(img_arr,(224,224))\n",
    "        x_train.append(img_arr)\n",
    "\n",
    "x_test=[]\n",
    "\n",
    "for folder in os.listdir(test_dir):\n",
    "    sub_dir=test_dir+\"/\"+folder\n",
    "    for img in os.listdir(sub_dir):\n",
    "        image_dir=sub_dir+\"/\"+img\n",
    "        img_arr=cv2.imread(image_dir)\n",
    "        img_arr=cv2.resize(img_arr,(224,224))\n",
    "        x_test.append(img_arr)\n",
    "\n",
    "x_valid=[]\n",
    "\n",
    "for folder in os.listdir(valid_dir):\n",
    "    sub_dir=valid_dir+\"/\"+folder\n",
    "    for img in os.listdir(sub_dir):\n",
    "        image_dir=sub_dir+\"/\"+img\n",
    "        img_arr=cv2.imread(image_dir)\n",
    "        img_arr=cv2.resize(img_arr,(224,224))\n",
    "        x_valid.append(img_arr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68b9544",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=np.array(x_train)/255.0\n",
    "test_x=np.array(x_test)/255.0\n",
    "valid_x=np.array(x_valid)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d626b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb52387",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=train_x.tolist()\n",
    "test_x=test_x.tolist()\n",
    "valid_x=valid_x.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9832c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3178b7ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_datagen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4952/412060795.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m training_set = train_datagen.flow_from_directory(train_dir,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                  \u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                  \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                  class_mode = 'sparse')\n\u001b[1;32m      5\u001b[0m test_set = test_datagen.flow_from_directory(test_dir,\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_datagen' is not defined"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(train_dir,\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'sparse')\n",
    "test_set = test_datagen.flow_from_directory(test_dir,\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'sparse')\n",
    "valid_set = valid_datagen.flow_from_directory(valid_dir,\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'sparse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f001446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a='''\n",
    "train_generator=train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "test_generator=test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "valid_generator=train_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bba2de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aadhaar': 0, 'dl': 1, 'pan': 2, 'voter': 3}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0ff91d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=training_set.classes\n",
    "test_y=test_set.classes\n",
    "valid_y=valid_set.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "252f07a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=train_y.tolist()\n",
    "test_y=test_y.tolist()\n",
    "valid_y=valid_y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e71c4fce",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29321/301428882.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "train_y.shape,test_y.shape,valid_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "def01b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "e='''model=Sequential()\n",
    "model.add(Conv2D(32,(3,3),padding='SAME',activation='relu',input_shape=(224,224,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),padding='SAME',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.summary()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aeb0d976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-22 13:11:07.551196: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-22 13:11:07.552679: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 28)      784       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 28)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 344988)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               44158592  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,160,666\n",
      "Trainable params: 44,160,666\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape=(224, 224,3)\n",
    "'''model=Sequential()\n",
    "#model.add(Conv2D(64,kernel_size=(3,3),input_shape=input_shape))\n",
    "model.add(Conv2D(32,(3,3),padding='SAME',activation='relu',input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation=tf.nn.relu))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10,activation=tf.nn.softmax))'''\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Conv2D(28,kernel_size=(3,3),input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation=tf.nn.relu))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10,activation=tf.nn.softmax))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1067b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])  \n",
    "model.compile(\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  optimizer=\"adam\",\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9eee4ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.8888 - accuracy: 0.3500 - val_loss: 82.4114 - val_accuracy: 0.2000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 51.0495 - accuracy: 0.4500 - val_loss: 97.0384 - val_accuracy: 0.4000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 1s 541ms/step - loss: 106.6549 - accuracy: 0.3000 - val_loss: 90.0215 - val_accuracy: 0.2000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 81.9613 - accuracy: 0.1500 - val_loss: 53.5819 - val_accuracy: 0.2000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 1s 550ms/step - loss: 37.9833 - accuracy: 0.4500 - val_loss: 96.2616 - val_accuracy: 0.2000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 46.4203 - accuracy: 0.5000 - val_loss: 66.3439 - val_accuracy: 0.2000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 34.6235 - accuracy: 0.4500 - val_loss: 44.7248 - val_accuracy: 0.6000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 1s 728ms/step - loss: 33.5206 - accuracy: 0.6000 - val_loss: 54.9930 - val_accuracy: 0.4000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 1s 768ms/step - loss: 41.7659 - accuracy: 0.4500 - val_loss: 38.6434 - val_accuracy: 0.4000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 26.4789 - accuracy: 0.4000 - val_loss: 16.8849 - val_accuracy: 0.4000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 1s 647ms/step - loss: 7.3907 - accuracy: 0.8500 - val_loss: 27.9785 - val_accuracy: 0.2000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 1s 703ms/step - loss: 13.3508 - accuracy: 0.7000 - val_loss: 24.4233 - val_accuracy: 0.4000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 7.4691 - accuracy: 0.6000 - val_loss: 9.3957 - val_accuracy: 0.4000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 3.0403 - accuracy: 0.8000 - val_loss: 7.7378 - val_accuracy: 0.4000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 1s 501ms/step - loss: 2.7204 - accuracy: 0.8000 - val_loss: 14.3680 - val_accuracy: 0.4000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 8.2122 - accuracy: 0.6500 - val_loss: 14.1725 - val_accuracy: 0.8000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 1s 963ms/step - loss: 8.3457 - accuracy: 0.6500 - val_loss: 11.1850 - val_accuracy: 0.8000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 2.6345 - accuracy: 0.8500 - val_loss: 7.5761 - val_accuracy: 0.8000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 0.2287 - accuracy: 0.9500 - val_loss: 4.1878 - val_accuracy: 0.8000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 1s 617ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 1.4229 - val_accuracy: 0.8000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 2.5818e-04 - accuracy: 1.0000 - val_loss: 1.1981 - val_accuracy: 0.8000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 1s 548ms/step - loss: 4.8397e-06 - accuracy: 1.0000 - val_loss: 4.1402 - val_accuracy: 0.6000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 1s 539ms/step - loss: 1.4782e-06 - accuracy: 1.0000 - val_loss: 7.3364 - val_accuracy: 0.4000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 9.1460 - val_accuracy: 0.4000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 0.3472 - accuracy: 0.9500 - val_loss: 8.3850 - val_accuracy: 0.4000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 0.0995 - accuracy: 0.9000 - val_loss: 5.7545 - val_accuracy: 0.4000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 3.7541 - val_accuracy: 0.4000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.3599e-04 - accuracy: 1.0000 - val_loss: 2.4579 - val_accuracy: 0.6000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 1s 643ms/step - loss: 5.1258e-06 - accuracy: 1.0000 - val_loss: 0.9357 - val_accuracy: 0.6000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 3.2663e-06 - accuracy: 1.0000 - val_loss: 0.2163 - val_accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history=model.fit(\n",
    "    np.array(train_x),\n",
    "    np.array(train_y),\n",
    "    validation_data=(valid_x,valid_y),\n",
    "    epochs=30,\n",
    ")\n",
    "\n",
    "#history=model.fit(training_set,\n",
    "#                  epochs=30,\n",
    "#                  validation_data=valid_set\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81bdfc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1f42b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('doc_datamodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60835334",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-22 13:11:54.990346: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-22 13:11:57.841750: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-22 13:11:57.845811: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import load_img,img_to_array\n",
    "import numpy as np\n",
    "\n",
    "model=load_model('doc_datamodel.h5')\n",
    "img_width,img_height=150,150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "618bf99a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30037/316440420.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpred_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/home/fansan/Desktop/Document-Classifier/testing/test1.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprediction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    908\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v2_behavior\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "pred_img=\"/home/fansan/Desktop/Document-Classifier/testing/test1.jpg\"\n",
    "prediction=model.predict(pred_img)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd96854",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bbde38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
